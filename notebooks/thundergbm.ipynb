{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "thundergbm_2_last.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvI_VjmwJHQK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "92a53e9e-ed88-4e29-8797-fcc17da6089e"
      },
      "source": [
        "!pip install thundergbm"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting thundergbm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/39/83/2b3823be05ecceaf0edcb666950dddcba9601ef764b22b6e99cea3259a98/thundergbm-0.3.16-py3-none-any.whl (2.8MB)\n",
            "\u001b[K     |████████████████████████████████| 2.8MB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from thundergbm) (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from thundergbm) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from thundergbm) (0.22.2.post1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->thundergbm) (0.16.0)\n",
            "Installing collected packages: thundergbm\n",
            "Successfully installed thundergbm-0.3.16\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9VtXnbeD4Rf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "67991d1d-811e-41b7-fc8b-0aea8878ec49"
      },
      "source": [
        "!pip install scikit-optimize"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/87/310b52debfbc0cb79764e5770fa3f5c18f6f0754809ea9e2fc185e1b67d3/scikit_optimize-0.7.4-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 12.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 30kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 51kB 2.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 61kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 71kB 3.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 2.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.16.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sp4Lx7duy_ua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import mean\n",
        "import os\n",
        "import time\n",
        "from scipy import interp\n",
        "\n",
        "from thundergbm import TGBMClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_curve, auc, roc_curve\n",
        "from sklearn.preprocessing import label_binarize, LabelEncoder\n",
        "\n",
        "from skopt.space import Integer\n",
        "from skopt.space import Real\n",
        "from skopt.utils import use_named_args\n",
        "from skopt import gp_minimize\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1sI61rMD1be",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "12a86dfd-499d-47ea-e924-67fa20401010"
      },
      "source": [
        "np.seterr(divide='ignore', invalid='ignore')\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'divide': 'warn', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxDiqAA0q8Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "files_path = '/path/to/datasets'"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dD8jQ4z8zDV8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files_list = os.listdir(files_path)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z06XTideOsN-",
        "colab_type": "text"
      },
      "source": [
        "# Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok7evSTc1ui5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def read_dataset(folder_path, filename):\n",
        "    df = pd.read_csv(os.path.join(folder_path, filename))\n",
        "    return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TyxkLMt_euW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dummy_encode(df):\n",
        "    \"\"\"  \n",
        "    one hot encoding to categorical columns\n",
        "    returns numpy array\n",
        "    \"\"\"\n",
        "\n",
        "    cols_to_encode = list(df.select_dtypes(include=['category','object']))\n",
        "    if len(cols_to_encode): \n",
        "        df = pd.get_dummies(df, columns = cols_to_encode, prefix=cols_to_encode)\n",
        "\n",
        "    return df.values"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urv8GdfyzOrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_data(df):\n",
        "    df = df.fillna(df.mean())\n",
        "    X = df.iloc[:, :-1]\n",
        "    y = df.iloc[:, -1]\n",
        "\n",
        "    lb = LabelEncoder()\n",
        "    y = lb.fit_transform(y)\n",
        "\n",
        "    X = dummy_encode(X)\n",
        "    classes = np.unique(y)\n",
        "\n",
        "    return X, y, classes"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8swPrrJD_HT",
        "colab_type": "text"
      },
      "source": [
        "# Metrics calculations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HatMK2f4zfys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def metrics_calc(y_true, y_pred, classes, clf):\n",
        "\n",
        "    # adding missing class in case the group labels are less than the initial classes size\n",
        "    if len(clf.group_label) < len(classes):\n",
        "        clf.group_label.extend(list(set(classes) - set(clf.group_label)))\n",
        "    y_true_label = label_binarize(y_true, clf.group_label)\n",
        "\n",
        "    if len(classes) > 2:\n",
        "        y_pred_arg = np.argmax(y_pred, axis=1)\n",
        "        cnf_matrix = confusion_matrix(np.argmax(y_true_label, axis=1),\n",
        "                                      y_pred_arg, \n",
        "                                      labels=sorted(clf.group_label))\n",
        "    else:\n",
        "        y_pred_arg = np.where(clf.predict_label > 0.5, 1, 0)\n",
        "        cnf_matrix = confusion_matrix(y_true, y_pred_arg)\n",
        "\n",
        "    fp = cnf_matrix.sum(axis=0) - np.diag(cnf_matrix)  \n",
        "    fn = cnf_matrix.sum(axis=1) - np.diag(cnf_matrix)\n",
        "    tp = np.diag(cnf_matrix)\n",
        "    tn = cnf_matrix.sum() - (fp + fn + tp)\n",
        "\n",
        "    fp = fp.astype(float)\n",
        "    fn = fn.astype(float)\n",
        "    tp = tp.astype(float)\n",
        "    tn = tn.astype(float)\n",
        "\n",
        "    tpr = tp/(tp+fn)\n",
        "    fpr = fp/(fp+tn)\n",
        "    precision = tp/(tp+fp)\n",
        "    acc = (tp+tn)/(tp+fp+fn+tn)\n",
        "\n",
        "    mean_acc = np.nanmean(acc)\n",
        "    mean_tpr = np.nanmean(tpr)\n",
        "    mean_fpr = np.nanmean(fpr)\n",
        "    mean_precision = np.nanmean(precision)\n",
        "\n",
        "    precision = dict()\n",
        "    recall = dict()\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc_list = []\n",
        "    pr_auc_list = []\n",
        "\n",
        "    if len(classes) == 2:\n",
        "        fpr, tpr, threshold_roc = roc_curve(y_true, y_pred)\n",
        "\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        roc_auc_list.append(roc_auc)\n",
        "\n",
        "        precision, recall, threshold_pr = precision_recall_curve(y_true,\n",
        "                                                            y_pred)\n",
        "\n",
        "        pr_auc = auc(recall, precision)\n",
        "\n",
        "        pr_auc_list.append(pr_auc)\n",
        "\n",
        "    else:\n",
        "        for i in range(y_pred.shape[1]):\n",
        "            fpr[i], tpr[i], threshold_roc = roc_curve(y_true_label[:, i], y_pred[:, i])\n",
        "            roc_auc = auc(fpr[i], tpr[i])\n",
        "            roc_auc_list.append(roc_auc)\n",
        "            \n",
        "            precision[i], recall[i], threshold_pr = precision_recall_curve(y_true_label[:, i],\n",
        "                                                                y_pred[:, i])\n",
        "            \n",
        "            pr_auc = auc(recall[i], precision[i])\n",
        "            pr_auc_list.append(pr_auc)\n",
        "\n",
        "    mean_roc_auc = np.nanmean(roc_auc_list)\n",
        "    mean_pr_auc = np.nanmean(pr_auc_list)\n",
        "\n",
        "    return mean_acc, mean_tpr, mean_fpr, mean_precision, mean_roc_auc, mean_pr_auc"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GHn5I9hg7aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', message='The objective has been evaluated at this point before.')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLZV3j03D8zq",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXEFkQXB1aIe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "254667bb-d0f8-4840-8244-a476bda9b153"
      },
      "source": [
        "for file in files_list:\n",
        "    print('file', file)\n",
        "\n",
        "    df = read_dataset(files_path, file)\n",
        "    df = df.iloc[:, 1:]\n",
        "\n",
        "    X, y, classes = prepare_data(df)\n",
        "\n",
        "    search_space = [Integer(4, 10 , name='depth', dtype=int),\n",
        "                    Integer(10, 80, name='n_trees', dtype=int)]\n",
        "\n",
        "    @use_named_args(search_space)\n",
        "    def evaluate_model(**params):\n",
        "        results = []\n",
        "        kf = KFold(n_splits=3, random_state=42, shuffle=True)\n",
        "        kf.get_n_splits(X)\n",
        "        for train_index, test_index in kf.split(X, y):\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "            clf = TGBMClassifier(num_class=len(classes),\n",
        "                                 objective=\"multi:softprob\")\n",
        "            clf.set_params(**params)\n",
        "\n",
        "            clf.fit(X_train, y_train)\n",
        "\n",
        "            y_proba = clf.predict(X_test)\n",
        "            prob_list = list(clf.predict_label_ptr)\n",
        "            # creating a numpy array filled with zeros with the size of the original classes\n",
        "            prob_array = np.zeros((X_test.shape[0], len(classes)))\n",
        "            # filling the probabilities results from the model to the numpy array\n",
        "            prob_array[:, :clf.num_class] = np.array(prob_list).reshape(clf.num_class, -1).T\n",
        "            y_pred = prob_array\n",
        "\n",
        "            group_classes = clf.group_label\n",
        "            result = accuracy_score(np.argmax(label_binarize(y_test, group_classes), axis=1),\n",
        "                                    y_pred.argmax(axis=1))\n",
        "            results.append(result)\n",
        "\n",
        "        # calculate the mean of the scores\n",
        "        estimate = mean(results)\n",
        "        return 1.0 - estimate\n",
        "\n",
        "    # perform optimization\n",
        "    result = gp_minimize(evaluate_model, search_space, n_calls=50)\n",
        "\n",
        "    print('Best Parameters: %s=%d, %s=%d' % (search_space[0].name, result.x[0],\n",
        "                                             search_space[1].name, result.x[1]))\n",
        "\n",
        "    best_params_vals = result.x\n",
        "    params_name = ['depth', 'n_trees']\n",
        "    best_params = dict(zip(params_name, best_params_vals))\n",
        "    \n",
        "    kf = KFold(n_splits=10, random_state=21, shuffle=True)\n",
        "    kf.get_n_splits(X)\n",
        "\n",
        "    acc_list = []\n",
        "    tpr_list = []\n",
        "    fpr_list = []\n",
        "    precision_list = []\n",
        "    roc_auc_list = []\n",
        "    pr_auc_list = []\n",
        "    training_time_list = []\n",
        "    inference_time_list = []\n",
        "    cross_val = []\n",
        "\n",
        "    for fold_num, data_index in enumerate(kf.split(X, y)):\n",
        "        train_index, test_index = data_index[0], data_index[1]\n",
        "        X_train, X_test = X[train_index], X[test_index]\n",
        "        y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "        clf = TGBMClassifier( objective=\"multi:softprob\")\n",
        "\n",
        "        clf.set_params(**best_params)\n",
        "        t0 = time.time()\n",
        "        clf.fit(X_train, y_train)\n",
        "        t1 = time.time()  \n",
        "        train_time = t1 - t0\n",
        "\n",
        "        t2 = time.time()\n",
        "        preds = clf.predict(X_test)\n",
        "        t3 = time.time()\n",
        "        inference_time = (t3 - t2) * 1000 / y_test.shape[0]\n",
        "\n",
        "        prob_list = list(clf.predict_label_ptr)\n",
        "\n",
        "        if len(classes) > 2:\n",
        "            prob_array = np.zeros((X_test.shape[0], len(classes)))\n",
        "            prob_array[:, :clf.num_class] = np.array(prob_list).reshape(clf.num_class, -1).T\n",
        "            y_pred = prob_array\n",
        "        else:\n",
        "            prob_array = np.zeros((X_test.shape[0], len(classes)))\n",
        "            prob_array[:, :clf.num_class] = np.array(prob_list).reshape(clf.num_class, -1).T\n",
        "            y_pred = prob_array\n",
        "            y_pred = preds\n",
        "\n",
        "        acc, mean_tpr, mean_fpr, mean_precision, mean_roc_auc, mean_pr_auc = metrics_calc(y_test, y_pred, classes, clf)\n",
        "        \n",
        "        acc_list.append(\"{:.3f}\".format(acc))\n",
        "        tpr_list.append(\"{:.3f}\".format(mean_tpr))\n",
        "        fpr_list.append(\"{:.3f}\".format(mean_fpr))\n",
        "        precision_list.append(\"{:.3f}\".format(mean_precision))\n",
        "        roc_auc_list.append(\"{:.3f}\".format(mean_roc_auc))\n",
        "        pr_auc_list.append(\"{:.3f}\".format(mean_pr_auc))\n",
        "        training_time_list.append(\"{:.1f}\".format(train_time))\n",
        "        inference_time_list.append(\"{:.1f}\".format(inference_time))\n",
        "\n",
        "        cross_val.append(fold_num + 1)\n",
        "\n",
        "    results_dict = {'Dataset Name':[file.split('.')[0]] * 10,\n",
        "                'Algorithm Name':['thundergbm'] * 10,\n",
        "                'Cross Validation':cross_val,\n",
        "                'Hyper Parameters Values': [best_params_vals] * 10,\n",
        "                'Accuracy':acc_list,\n",
        "                'tpr':tpr_list,\n",
        "                'FPR':fpr_list,\n",
        "                'Precision':precision_list,\n",
        "                'AUC':roc_auc_list,\n",
        "                'PR-Curve':pr_auc_list,\n",
        "                'Training Time':training_time_list,\n",
        "                'Inference Time':inference_time_list\n",
        "                }\n",
        "\n",
        "    df = pd.DataFrame.from_dict(results_dict)\n",
        "    df = df.fillna(0)\n",
        "\n",
        "    df.to_csv('path/to/results/file',\n",
        "              mode='a', header=False)\n",
        "\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file analcatdata_lawsuit.csv\n",
            "Best Parameters: depth=6, n_trees=51\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_ranking.py:808: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
            "  UndefinedMetricWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: RuntimeWarning: Mean of empty slice\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:71: RuntimeWarning: Mean of empty slice\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ce-qnrZZ6ul3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCIdjWz6bZYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}